{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686eadb5-0a0f-4653-9947-6a3bb54fa353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afb6142-de0c-447d-b0e2-b39bd2e12f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Assume CIFAR data has mean 0.5 & standard deviation 0.25\n",
    "x_mean = 0.5\n",
    "x_sd = 0.25\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50bed38-9f59-49e8-ab75-1c06da1e75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img * x_sd + x_mean\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7b7b31-fb78-43d3-b37d-679720fab6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.norm1 = nn.BatchNorm2d(6)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.norm3 = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.norm4 = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(\n",
    "            self.norm1(F.relu(self.conv1(x)))\n",
    "        )\n",
    "        x = self.pool2(\n",
    "            self.norm2(F.relu(self.conv2(x)))\n",
    "        )\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.norm3(F.relu(self.fc1(x)))\n",
    "        x = self.norm4(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a04d16-2dff-4402-bccc-d8a74aae5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # Convert Pillow images to tensors\n",
    "    transforms.ToTensor(),\n",
    "    # Shooting for mean = 0, sd = 0.5\n",
    "    transforms.Normalize((x_mean, x_mean, x_mean), (x_sd, x_sd, x_sd))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8476e216-5a01-4465-9063-bee02cc02952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ea74e0-edcd-4947-a880-297406f48b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b6dba2-6928-4bb0-a120-27a8b1b03d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee61753e-5524-489f-95be-744ca3854a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08deb615-1247-4fa9-bad8-d0c01ed59d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29e1019-a893-4cc4-8f7d-a6015b5ff585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90db903d-140f-45a5-a1cb-2bd77abee94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7959a61e-6caf-4958-94d7-d3f793349585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1000] avg. train loss: 1.755, running train loss: 1.414\n",
      "[1, 2000] avg. train loss: 1.664, running train loss: 1.553\n",
      "[1, 3000] avg. train loss: 1.616, running train loss: 1.502\n",
      "[1] val. accuracy: 51.38\n",
      "[2, 1000] avg. train loss: 1.401, running train loss: 1.157\n",
      "[2, 2000] avg. train loss: 1.376, running train loss: 1.161\n",
      "[2, 3000] avg. train loss: 1.359, running train loss: 1.843\n",
      "[2] val. accuracy: 55.05\n",
      "[3, 1000] avg. train loss: 1.242, running train loss: 1.137\n",
      "[3, 2000] avg. train loss: 1.228, running train loss: 1.076\n",
      "[3, 3000] avg. train loss: 1.22, running train loss: 1.177\n",
      "[3] val. accuracy: 61.32\n",
      "[4, 1000] avg. train loss: 1.147, running train loss: 1.328\n",
      "[4, 2000] avg. train loss: 1.139, running train loss: 0.908\n",
      "[4, 3000] avg. train loss: 1.139, running train loss: 1.406\n",
      "[4] val. accuracy: 61.63\n",
      "[5, 1000] avg. train loss: 1.075, running train loss: 0.842\n",
      "[5, 2000] avg. train loss: 1.074, running train loss: 0.791\n",
      "[5, 3000] avg. train loss: 1.081, running train loss: 1.036\n",
      "[5] val. accuracy: 63.37\n",
      "[6, 1000] avg. train loss: 1.011, running train loss: 1.226\n",
      "[6, 2000] avg. train loss: 1.05, running train loss: 0.878\n",
      "[6, 3000] avg. train loss: 1.047, running train loss: 0.859\n",
      "[6] val. accuracy: 63.38\n",
      "[7, 1000] avg. train loss: 0.98, running train loss: 0.709\n",
      "[7, 2000] avg. train loss: 0.983, running train loss: 0.897\n",
      "[7, 3000] avg. train loss: 0.99, running train loss: 0.714\n",
      "[7] val. accuracy: 63.99\n",
      "[8, 1000] avg. train loss: 0.962, running train loss: 1.104\n",
      "[8, 2000] avg. train loss: 0.956, running train loss: 1.001\n",
      "[8, 3000] avg. train loss: 0.957, running train loss: 0.542\n",
      "[8] val. accuracy: 65.07\n",
      "[9, 1000] avg. train loss: 0.92, running train loss: 0.509\n",
      "[9, 2000] avg. train loss: 0.93, running train loss: 1.376\n",
      "[9, 3000] avg. train loss: 0.929, running train loss: 1.168\n",
      "[9] val. accuracy: 65.27\n",
      "[10, 1000] avg. train loss: 0.883, running train loss: 1.1\n",
      "[10, 2000] avg. train loss: 0.89, running train loss: 0.642\n",
      "[10, 3000] avg. train loss: 0.896, running train loss: 0.835\n",
      "[10] val. accuracy: 65.82\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # Train\n",
    "    net.train()\n",
    "    total_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        running_loss = loss.item()\n",
    "        # Divide total loss by number of mini batches\n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        \n",
    "        if i % 1000 == 999:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] avg. train loss: {np.round(avg_loss, 3)}, running train loss: {np.round(running_loss, 3)}\")\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "            \n",
    "    # Eval\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            # Returns (value, index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"[{epoch + 1}] val. accuracy: {np.round(correct / total * 100, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbf67b-dff0-4506-bb85-aa219fa5dfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
