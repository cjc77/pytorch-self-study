{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db1abdce-57f8-4702-84c4-3e9ba6e76d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1452315e-7381-422e-9865-bd38f7123118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter):\n",
    "    \"\"\"Convert raw text into a flat Tensor.\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        torch.tensor(vocab(tokenizer(item)), dtype=torch.long)\n",
    "        for item in raw_text_iter\n",
    "    ]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "\n",
    "def batchify(data, bsz, device):\n",
    "    \"\"\"Divides data into 'bsz' separate sequences & removes extra elements\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b34fd7d-1a19-4aa0-994e-5442a2ab8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_tokens, n_heads, d_model, d_hid, n_layers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.model_type == \"Transformer\"\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model, n_heads, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoderLayer(encoder_layer, n_layers)\n",
    "        self.encoder = nn.Embedding(n_tokens, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, n_tokens)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "            \n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "417f8e5f-a276-4f4a-a649-aecb5b3cb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split=\"train\")\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38086558-002f-4f37-b69f-7d9ebeba3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a57abb00-7058-48bf-b91f-ed54a650c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 20\n",
    "eval_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d4ba98c-c03a-4656-a599-b86a6f543840",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = batchify(train_data, batch_size, device)\n",
    "val_data = batchify(val_data, eval_batch_size, device)\n",
    "test_data = batchify(test_data, eval_batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbef1e77-2b9f-49e1-b5b4-c140c217c0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24185, 10])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
