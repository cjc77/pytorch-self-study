{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1abdce-57f8-4702-84c4-3e9ba6e76d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1452315e-7381-422e-9865-bd38f7123118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter):\n",
    "    \"\"\"Convert raw text into a flat Tensor.\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        torch.tensor(vocab(tokenizer(item)), dtype=torch.long)\n",
    "        for item in raw_text_iter\n",
    "    ]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "\n",
    "def batchify(data, bsz, device):\n",
    "    \"\"\"Divides data into 'bsz' separate sequences & removes extra elements\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"Generate upper-triangular matrix of ``-inf`` with zeros on the diagonal.\n",
    "    \"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float(\"-inf\"), diagonal=1)\n",
    "\n",
    "\n",
    "def get_batch(x_src, i, bptt=35):\n",
    "    \"\"\"\n",
    "    x_src is a tensor of shape (full_seq_len, batch_size).\n",
    "    \n",
    "    Returns a tuple (data, target) where data has shape (seq_len, batch_size) and\n",
    "    target has shape (seq_len * batch_size)\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(x_src) - 1 - i)\n",
    "    data = x_src[i: i + seq_len]\n",
    "    target = x_src[(i + 1): (i + 1 + seq_len)].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b34fd7d-1a19-4aa0-994e-5442a2ab8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_tokens, d_model, n_heads, d_hid, n_layers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.encoder = nn.Embedding(n_tokens, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model, n_heads, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, n_layers)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, n_tokens)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "\n",
    "    def forward(self, x_src, x_src_mask):\n",
    "        x_src = self.encoder(x_src) * np.sqrt(self.d_model)\n",
    "        x_src = self.pos_encoder(x_src)\n",
    "        x_dest = self.transformer_encoder(x_src, x_src_mask)\n",
    "        x_dest = self.decoder(x_dest)\n",
    "        return x_dest\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        # Odd positions\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        # Even positions\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is a tensor of shape (seq_len, batch_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "417f8e5f-a276-4f4a-a649-aecb5b3cb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split=\"train\")\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38086558-002f-4f37-b69f-7d9ebeba3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a57abb00-7058-48bf-b91f-ed54a650c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 20\n",
    "eval_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4ba98c-c03a-4656-a599-b86a6f543840",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = batchify(train_data, batch_size, device)\n",
    "val_data = batchify(val_data, eval_batch_size, device)\n",
    "test_data = batchify(test_data, eval_batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbef1e77-2b9f-49e1-b5b4-c140c217c0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([102499, 20])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "343d266b-1b63-43f8-9e89-fe868409908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of vocab\n",
    "n_tokens = len(vocab)\n",
    "# Embedding dimension\n",
    "emsize = 200\n",
    "# Dimension size of feed forward network in TransformerEncoder\n",
    "d_hid = 200\n",
    "# Number of TransformerEncoderLayer in TransformerEncoder\n",
    "n_layers = 2\n",
    "# Number of heads in MultiheadAttention\n",
    "n_head = 2\n",
    "# Dropout probability (used by all network modules)\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14f367e0-b866-42be-94ec-63a676efe1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(n_tokens, emsize, n_head, d_hid, n_layers, dropout).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
