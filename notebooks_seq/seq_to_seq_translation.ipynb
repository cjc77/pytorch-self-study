{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88de0b6-ff8a-47da-a4cc-05ced90bb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95c5639-875c-483c-bcec-a2b32c7f6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ff3ef8-774d-4349-a2d6-d9117edf062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4637bfb-6199-40af-a9ae-b2e48c421531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, x, h0):\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        x = embedded\n",
    "        x, h = self.gru(x, h0)\n",
    "        return x, h\n",
    "    \n",
    "    def zero_hidden(self, device):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "# TODO: try training a simple seq-to-seq model\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Input & output size are the same (since they are word embeddings)\n",
    "        self.input_size = input_size\n",
    "        self.output_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, h0):\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        x = F.relu(embedded)\n",
    "        x, h = self.gru(x, h0)\n",
    "        # GRU output has leading batch dimension, so index x[0]\n",
    "        x = self.out(x[0])\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def zero_hidden(self, device):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    \n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, max_length, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        # Weights for each word in sentence of max length\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(p = self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x, h0, yhats_encoder):\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        x = torch.concat((embedded[0], h0[0]), dim=1)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(x),\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        # unsqueeze(0) --> add 'batch' dimension back to\n",
    "        # attention weights & add to encoder outputs\n",
    "        attn_applied = torch.bmm(\n",
    "            attn_weights.unsqueeze(0),\n",
    "            yhats_encoder.unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        # subscript embedded & attn_applied to emove 'batch' dimension\n",
    "        x = torch.concat((embedded[0], attn_applied[0]), dim=1)\n",
    "        # unsqueeze result to add 'batch' dimension back in\n",
    "        x = self.attn_combine(x).unsqueeze(0)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x, h = self.gru(x, h0)\n",
    "        # GRU output has leading batch dimension, so index x[0]\n",
    "        x = self.out(x[0])\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x, h, attn_weights\n",
    "    \n",
    "    def zero_hidden(self, device):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7f4db68-2408-4c29-9076-79307be3ab71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    \"\"\"Turn a Unicode string to plain ASCII.\n",
    "    \"\"\"\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s)\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    \"\"\"Lowercase, trim, and remove non-letter characters.\n",
    "    \"\"\"\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def read_langs(lang1, lang2, data_path=\"../data/rnn_seq_to_seq_data\", reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Read file & split into lines\n",
    "    lines = open(f\"{data_path}/{lang1}-{lang2}.txt\", encoding=\"utf-8\").read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def filter_pair(p, max_length, eng_prefixes):\n",
    "    return len(p[0].split(\" \")) < max_length and \\\n",
    "        len(p[1].split(\" \")) < max_length and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filter_pairs(pairs, max_length, eng_prefixes):\n",
    "    return [pair for pair in pairs if filter_pair(pair, max_length, eng_prefixes)]\n",
    "\n",
    "\n",
    "def prepare_data(lang1, lang2, max_length, eng_prefixes, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1, lang2, reverse=reverse)\n",
    "    print(f\"Read {len(pairs)} sentence pairs\")\n",
    "    pairs = filter_pairs(pairs, max_length, eng_prefixes)\n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "\n",
    "def tensor_from_sentence(lang, sentence, device):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensor_from_pairs(pair, input_lang, output_lang, device):\n",
    "    input_tensor = tensor_from_sentence(input_lang, pair[0], device)\n",
    "    target_tensor = tensor_from_sentence(output_lang, pair[1], device)\n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "\n",
    "def train(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, input_tensor, target_tensor, max_length, device, teacher_forcing_ratio=0.5):\n",
    "    h_encoder = encoder.zero_hidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.shape[0]\n",
    "    target_length = target_tensor.shape[0]\n",
    "    \n",
    "    yhats_encoder = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0.0\n",
    "    for ei in range(input_length):\n",
    "        yhat_encoder, h_encoder = encoder(input_tensor[ei], h_encoder)\n",
    "        yhats_encoder[ei] = yhat_encoder[0, 0]\n",
    "        \n",
    "    x_decoder = torch.tensor([[SOS_token]], device=device)\n",
    "    h_decoder = h_encoder\n",
    "    \n",
    "    use_teacher_forcing = True if np.random.uniform() < teacher_forcing_ratio else False\n",
    "    \n",
    "    # Teacher forcing = feed target in as next input\n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            # Pass in full encoder output\n",
    "            yhat_decoder, h_decoder, attn_decoder = decoder(x_decoder, h_decoder, yhats_encoder)\n",
    "            loss += criterion(yhat_decoder, target_tensor[di])\n",
    "            \n",
    "            x_decoder = target_tensor[di]\n",
    "    # Non-teacher forcing = feed previous output of decoder as input\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            yhat_decoder, h_decoder, attn_decoder = decoder(x_decoder, h_decoder, yhats_encoder) \n",
    "            loss += criterion(yhat_decoder, target_tensor[di])\n",
    "            \n",
    "            topv, topi = yhat_decoder.topk(1)\n",
    "            # When used as input, should be detached from backprop history\n",
    "            x_decoder = topi.squeeze().detach()\n",
    "            if x_decoder.item() == EOS_token:\n",
    "                break\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3860a6e6-282e-43ea-97dd-2ea53b8bc7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37291441617784726"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3806272d-3b50-436b-84f6-963aee3b2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f0b5fa-2c2b-4fb2-9800-43d03d3bea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data(\"eng\", \"fra\", MAX_LENGTH, eng_prefixes, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7113c01-6cc4-4cb8-93ca-d6ce70149e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elle est assez grande pour voyager toute seule .',\n",
       " 'she is old enough to travel by herself .']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
